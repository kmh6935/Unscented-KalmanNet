{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b567c529",
   "metadata": {},
   "source": [
    "# Toy UKF + Causal Window Transformer NoiseNet (Full Cholesky Qx/R + pₖ→Qθ Gating)\n",
    "\n",
    "This notebook implements a **minimal end-to-end toy** for your setup:\n",
    "\n",
    "- **2-DOF** dynamics with state \\(x=[q_1,q_2,v_1,v_2]\\) (nx=4) and measurement \\(y=[q_1,q_2]\\) (ny=2)  \n",
    "- **Augmented state** \\(z=[x;\\theta]\\) with a **single parameter** \\(\\theta\\) scaling stiffness  \n",
    "- Sequence length **T=2000**, random change-point \\(k^*\\), and **+30% step jump** in \\(\\theta\\)  \n",
    "- A **causal Transformer** predicts **full SPD** \\(Q_{x,k}\\) and \\(R_k\\) via **Cholesky factors**, plus a change logit \\(p_k\\)  \n",
    "- \\(p_k\\) gates \\(Q_{\\theta,k}\\) inside the UKF predict covariance:\n",
    "  \\[\n",
    "  Q_{\\theta,k}=(1-\\sigma(p_k))Q_{\\theta}^{\\text{base}}+\\sigma(p_k)Q_{\\theta}^{\\text{jump}}\n",
    "  \\]\n",
    "- Training uses **sliding windows** with **burn-in**, **state supervision**, and **BCE supervision** for change detection.\n",
    "\n",
    "> Tip: Start with the default small training settings to sanity-check. Then increase epochs/steps to improve adaptation speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0c772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0+cu128\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Setup ---\n",
    "from __future__ import annotations\n",
    "import math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccccf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFG(device='cuda', dtype=torch.float32, nx=4, ny=2, nt=1, nz=5, dt=0.02, T=2000, jump_ratio=0.3, kstar_lo=0.3, kstar_hi=0.7, alpha=1.0, beta=0.0, kappa=0.0, jitter_P=0.001, jitter_S=1e-06, W=128, d_model=128, n_layers=2, n_heads=4, dropout=0.1, burn_in=128, L=256, batch_size=32, n_train_seq=256, n_val_seq=64, n_test_seq=64, lr=0.0003, epochs=3, steps_per_epoch=100, w_state=1.0, w_bce=0.2, w_smooth=0.0001, w_offdiag=0.0001, Qtheta_base=1e-08, Qtheta_jump=0.0001, p_label_width=25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Config ---\n",
    "@dataclass\n",
    "class CFG:\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype: torch.dtype = torch.float32\n",
    "\n",
    "    # problem dims\n",
    "    nx: int = 4\n",
    "    ny: int = 2\n",
    "    nt: int = 1\n",
    "    nz: int = 5\n",
    "\n",
    "    # simulation\n",
    "    dt: float = 0.02\n",
    "    T: int = 2000\n",
    "    jump_ratio: float = 0.30\n",
    "    kstar_lo: float = 0.3\n",
    "    kstar_hi: float = 0.7\n",
    "\n",
    "    # UKF params\n",
    "    alpha: float = 1.0\n",
    "    beta: float = 0.0\n",
    "    kappa: float = 0.0\n",
    "    jitter_P: float = 1e-3\n",
    "    jitter_S: float = 1e-6\n",
    "\n",
    "    # NoiseNet / Transformer\n",
    "    W: int = 128              # sliding window length for features (past-only)\n",
    "    d_model: int = 128\n",
    "    n_layers: int = 2\n",
    "    n_heads: int = 4\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # Training windows (burn-in + loss)\n",
    "    burn_in: int = 128\n",
    "    L: int = 256\n",
    "\n",
    "    # Dataset sizes\n",
    "    batch_size: int = 32\n",
    "\n",
    "    n_train_seq: int = 128*2\n",
    "    n_val_seq: int = 32*2\n",
    "    n_test_seq: int = 32*2\n",
    "\n",
    "    # Training (keep small for sanity-check; increase later)\n",
    "    lr: float = 3e-4\n",
    "    epochs: int = 3\n",
    "    steps_per_epoch: int = 100\n",
    "\n",
    "    # Loss weights\n",
    "    w_state: float = 1.0\n",
    "    w_bce: float = 0.2\n",
    "    w_smooth: float = 1e-4\n",
    "    w_offdiag: float = 1e-4\n",
    "\n",
    "    # Q_theta gating (variance)\n",
    "    Qtheta_base: float = 1e-8\n",
    "    Qtheta_jump: float = 1e-4   # increase (e.g., 1e-3) for faster adaptation if stable\n",
    "\n",
    "    # label width after change (p_k uses features up to k-1, so label starts at k*+1)\n",
    "    p_label_width: int = 25\n",
    "\n",
    "cfg = CFG()\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b4f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Utilities: Cholesky parameterization for full SPD Qx and R ---\n",
    "\n",
    "def n_tril(n: int) -> int:\n",
    "    return n * (n + 1) // 2\n",
    "\n",
    "\n",
    "def vec_to_cholesky(v: torch.Tensor, n: int, eps: float = 1e-4,\n",
    "                    diag_min: float = -12.0, diag_max: float = 6.0,\n",
    "                    off_clip: float = 3.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    v: (..., n_tril(n)) lower-triangular params\n",
    "       convention: first n entries -> diag logits, remaining -> strict-lower row-wise\n",
    "    returns L: (..., n, n) with positive diag (via softplus)\n",
    "\n",
    "    Safety:\n",
    "      - nan/inf -> 0\n",
    "      - diag logits clamped to [diag_min, diag_max]\n",
    "      - off-diagonals clipped to [-off_clip, off_clip]\n",
    "    \"\"\"\n",
    "    v = torch.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    diag_logits = torch.clamp(v[..., :n], min=diag_min, max=diag_max)\n",
    "    off = torch.clamp(v[..., n:], min=-off_clip, max=off_clip)\n",
    "\n",
    "    L = v.new_zeros(*v.shape[:-1], n, n)\n",
    "    diag = F.softplus(diag_logits) + eps\n",
    "    idx = torch.arange(n, device=v.device)\n",
    "    L[..., idx, idx] = diag\n",
    "\n",
    "    k = 0\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            L[..., i, j] = off[..., k]\n",
    "            k += 1\n",
    "    return L\n",
    "\n",
    "\n",
    "def chol_to_spd(L: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    n = L.shape[-1]\n",
    "    I = torch.eye(n, device=L.device, dtype=L.dtype)\n",
    "    return L @ L.transpose(-1, -2) + eps * I\n",
    "\n",
    "def blockdiag(Qx: torch.Tensor, Qt: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Qx: (B,nx,nx), Qt: (B,nt,nt) -> Qz: (B,nz,nz)\n",
    "    \"\"\"\n",
    "    B, nx, _ = Qx.shape\n",
    "    _, nt, _ = Qt.shape\n",
    "    Qz = Qx.new_zeros(B, nx + nt, nx + nt)\n",
    "    Qz[:, :nx, :nx] = Qx\n",
    "    Qz[:, nx:, nx:] = Qt\n",
    "    return Qz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bceaa514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Physics: 2-DOF model (theta scales the coupling stiffness) ---\n",
    "\n",
    "def build_mck(theta: torch.Tensor, device, dtype) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    theta: (B,1) stiffness scale for coupling spring\n",
    "    Returns M,C,K for each batch as (B,2,2)\n",
    "    \"\"\"\n",
    "    B = theta.shape[0]\n",
    "    m1, m2 = 1.0, 1.0\n",
    "    c1, c2, cc = 0.05, 0.05, 0.02\n",
    "    k1, k2 = 20.0, 20.0\n",
    "    kc0 = 15.0\n",
    "    kc = kc0 * theta.squeeze(-1)  # (B,)\n",
    "\n",
    "    M = torch.tensor([[m1, 0.0],[0.0, m2]], device=device, dtype=dtype).expand(B,2,2).clone()\n",
    "\n",
    "    # Damping: C = [[c1+cc, -cc],[-cc, c2+cc]]\n",
    "    C = torch.zeros(B,2,2, device=device, dtype=dtype)\n",
    "    C[:,0,0] = c1 + cc\n",
    "    C[:,1,1] = c2 + cc\n",
    "    C[:,0,1] = -cc\n",
    "    C[:,1,0] = -cc\n",
    "\n",
    "    # Stiffness: K = [[k1+kc, -kc],[-kc, k2+kc]]\n",
    "    K = torch.zeros(B,2,2, device=device, dtype=dtype)\n",
    "    K[:,0,0] = k1 + kc\n",
    "    K[:,1,1] = k2 + kc\n",
    "    K[:,0,1] = -kc\n",
    "    K[:,1,0] = -kc\n",
    "    return M, C, K\n",
    "\n",
    "def f_step(z: torch.Tensor, dt: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    z: (B, nz) = [q1,q2,v1,v2,theta]\n",
    "    deterministic transition (no noise added here)\n",
    "    \"\"\"\n",
    "    device, dtype = z.device, z.dtype\n",
    "    q = z[:, 0:2]            # (B,2)\n",
    "    v = z[:, 2:4]            # (B,2)\n",
    "    theta = z[:, 4:5]        # (B,1)\n",
    "\n",
    "    M, C, K = build_mck(theta, device, dtype)\n",
    "    Minv = torch.linalg.inv(M)\n",
    "\n",
    "    a = -(Minv @ (C @ v.unsqueeze(-1) + K @ q.unsqueeze(-1))).squeeze(-1)  # (B,2)\n",
    "\n",
    "    q_next = q + dt * v\n",
    "    v_next = v + dt * a\n",
    "    theta_next = theta  # random-walk handled via Q_theta in the filter\n",
    "\n",
    "    return torch.cat([q_next, v_next, theta_next], dim=-1)\n",
    "\n",
    "def h_meas(z: torch.Tensor) -> torch.Tensor:\n",
    "    # measurement: y = [q1,q2]\n",
    "    return z[:, 0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28670f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- Simulation: T=2000 with random k* and +30% step jump in theta ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def simulate_sequence(T: int, dt: float, jump_ratio: float, kstar: int, device, dtype):\n",
    "    \"\"\"\n",
    "    Generates x_true (T,nx), theta_true (T,1), y (T,ny)\n",
    "    \"\"\"\n",
    "    theta0 = 1.0\n",
    "    theta1 = theta0 * (1.0 + jump_ratio)  # +30% at/after k*\n",
    "    theta_true = torch.full((T,1), theta0, device=device, dtype=dtype)\n",
    "    theta_true[kstar:, 0] = theta1\n",
    "\n",
    "    # initial state\n",
    "    q0 = torch.tensor([0.2, -0.1], device=device, dtype=dtype)\n",
    "    v0 = torch.tensor([0.0, 0.0], device=device, dtype=dtype)\n",
    "    x = torch.cat([q0, v0]).unsqueeze(0)  # (1,4)\n",
    "\n",
    "    # simulation noises\n",
    "    Qsim = torch.diag(torch.tensor([1e-6,1e-6,1e-5,1e-5], device=device, dtype=dtype))\n",
    "    Lsim = torch.linalg.cholesky(Qsim)\n",
    "\n",
    "    Rsim = torch.diag(torch.tensor([2e-4, 2e-4], device=device, dtype=dtype))\n",
    "    Lr = torch.linalg.cholesky(Rsim)\n",
    "\n",
    "    x_true = torch.zeros(T,4, device=device, dtype=dtype)\n",
    "    y = torch.zeros(T,2, device=device, dtype=dtype)\n",
    "\n",
    "    for k in range(T):\n",
    "        th = theta_true[k:k+1]  # (1,1)\n",
    "        z = torch.cat([x, th], dim=-1)  # (1,5)\n",
    "\n",
    "        z_next = f_step(z, dt=dt)\n",
    "        x_next = z_next[:, :4]\n",
    "        x_next = x_next + (torch.randn(1,4, device=device, dtype=dtype) @ Lsim.T)\n",
    "        x = x_next\n",
    "\n",
    "        x_true[k] = x.squeeze(0)\n",
    "        y[k] = x_true[k, :2] + (torch.randn(2, device=device, dtype=dtype) @ Lr.T)\n",
    "\n",
    "    return x_true, theta_true, y\n",
    "\n",
    "def make_p_label(T: int, kstar: int, width: int, device, dtype):\n",
    "    # label starts at kstar+1 because p_k is predicted from phi up to k-1\n",
    "    start = min(T-1, kstar + 1)\n",
    "    end = min(T, start + width)\n",
    "    p = torch.zeros(T,1, device=device, dtype=dtype)\n",
    "    p[start:end, 0] = 1.0\n",
    "    return p\n",
    "\n",
    "# quick sanity-check visualization of one simulated sequence\n",
    "device, dtype = cfg.device, cfg.dtype\n",
    "kstar = random.randint(int(cfg.kstar_lo*cfg.T), int(cfg.kstar_hi*cfg.T))\n",
    "x_true, theta_true, y = simulate_sequence(cfg.T, cfg.dt, cfg.jump_ratio, kstar, device, dtype)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(theta_true.cpu().numpy())\n",
    "plt.title(f\"True theta (k*={kstar})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d157200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_cholesky(A: torch.Tensor, jitter: float = 1e-6, max_tries: int = 8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Robust Cholesky with increasing diagonal loading + nan/inf sanitization.\n",
    "    \"\"\"\n",
    "    A = torch.nan_to_num(A, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    A = 0.5 * (A + A.transpose(-1,-2))\n",
    "    n = A.shape[-1]\n",
    "    I = torch.eye(n, device=A.device, dtype=A.dtype).unsqueeze(0)\n",
    "    for i in range(max_tries):\n",
    "        try:\n",
    "            return torch.linalg.cholesky(A + (jitter * (10.0**i)) * I)\n",
    "        except Exception:\n",
    "            continue\n",
    "    # fallback: eigen projection\n",
    "    w, V = torch.linalg.eigh(A)\n",
    "    w = torch.clamp(w, min=jitter)\n",
    "    A_spd = V @ torch.diag_embed(w) @ V.transpose(-1,-2)\n",
    "    return torch.linalg.cholesky(A_spd + jitter*I)\n",
    "\n",
    "\n",
    "\n",
    "# --- Innovation features phi_k = [L^{-1}e, |L^{-1}e|, NIS, logdetS] ---\n",
    "\n",
    "def make_phi(e: torch.Tensor, S: torch.Tensor, jitter: float = 1e-6) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    e: (B,ny)\n",
    "    S: (B,ny,ny) SPD\n",
    "    returns phi: (B, d_in) = [e_white, |e_white|, nis, logdetS]\n",
    "    \"\"\"\n",
    "    B, ny = e.shape\n",
    "    I = torch.eye(ny, device=e.device, dtype=e.dtype).unsqueeze(0)\n",
    "    S = S + jitter * I\n",
    "    L = safe_cholesky(S, jitter=jitter)  # (B,ny,ny)\n",
    "    # e_white = L^{-1} e\n",
    "    e_white = torch.linalg.solve_triangular(L, e.unsqueeze(-1), upper=False).squeeze(-1)\n",
    "    nis = (e_white**2).sum(dim=-1, keepdim=True)\n",
    "    logdetS = 2.0 * torch.log(torch.diagonal(L, dim1=-2, dim2=-1)).sum(dim=-1, keepdim=True)\n",
    "    phi = torch.cat([e_white, e_white.abs(), nis, logdetS], dim=-1)\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515f7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sanitize_sym(A: torch.Tensor) -> torch.Tensor:\n",
    "    A = torch.nan_to_num(A, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return 0.5 * (A + A.transpose(-1,-2))\n",
    "\n",
    "def make_spd(A: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    A = sanitize_sym(A)\n",
    "    w, V = torch.linalg.eigh(A)\n",
    "    w = torch.clamp(w, min=eps)\n",
    "    return V @ torch.diag_embed(w) @ V.transpose(-1,-2) + eps * torch.eye(A.shape[-1], device=A.device, dtype=A.dtype)\n",
    "\n",
    "def safe_cholesky(A: torch.Tensor, jitter: float = 1e-6, max_tries: int = 8) -> torch.Tensor:\n",
    "    A = sanitize_sym(A)\n",
    "    n = A.shape[-1]\n",
    "    I = torch.eye(n, device=A.device, dtype=A.dtype).unsqueeze(0)\n",
    "    for i in range(max_tries):\n",
    "        try:\n",
    "            return torch.linalg.cholesky(A + (jitter * (10.0**i)) * I)\n",
    "        except Exception:\n",
    "            continue\n",
    "    # fallback: eigen projection then cholesky\n",
    "    A = make_spd(A, eps=jitter)\n",
    "    return torch.linalg.cholesky(A + jitter * I)\n",
    "\n",
    "\n",
    "\n",
    "def make_spd(A: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Project a symmetric matrix to SPD by clamping eigenvalues.\n",
    "    A: (B,n,n)\n",
    "    \"\"\"\n",
    "    A = 0.5 * (A + A.transpose(-1, -2))\n",
    "    w, V = torch.linalg.eigh(A)\n",
    "    w = torch.clamp(w, min=eps)\n",
    "    return V @ torch.diag_embed(w) @ V.transpose(-1, -2)\n",
    "\n",
    "\n",
    "\n",
    "# --- UKF step (batched) ---\n",
    "\n",
    "def ukf_step(z: torch.Tensor, P: torch.Tensor, y: torch.Tensor, Qz: torch.Tensor, R: torch.Tensor,\n",
    "            dt: float, alpha: float, beta: float, kappa: float,\n",
    "            jitter_P: float, jitter_S: float):\n",
    "    \"\"\"\n",
    "    z: (B,nz) mean\n",
    "    P: (B,nz,nz)\n",
    "    y: (B,ny)\n",
    "    Qz: (B,nz,nz)\n",
    "    R:  (B,ny,ny)\n",
    "    Returns z_upd, P_upd, innovation e, S\n",
    "    \"\"\"\n",
    "    device, dtype = z.device, z.dtype\n",
    "    B, nz = z.shape\n",
    "    ny = y.shape[-1]\n",
    "\n",
    "    lam = alpha**2 * (nz + kappa) - nz\n",
    "    c = nz + lam\n",
    "    Wm0 = lam / c\n",
    "    Wc0 = Wm0 + (1 - alpha**2 + beta)\n",
    "    W = 1.0 / (2.0 * c)\n",
    "\n",
    "    # cholesky of P\n",
    "    I = torch.eye(nz, device=device, dtype=dtype).unsqueeze(0)\n",
    "    Pj = make_spd(P, eps=jitter_P)\n",
    "    U = safe_cholesky(P, jitter=jitter_P)  # robust (B,nz,nz) lower\n",
    "    U = U * math.sqrt(c)\n",
    "\n",
    "    # sigma points\n",
    "    sigmas = z.unsqueeze(1).repeat(1, 2*nz+1, 1)\n",
    "    Ucols = U.transpose(-1, -2)  # each row = a column of U\n",
    "    sigmas[:, 1:nz+1, :] = z.unsqueeze(1) + Ucols\n",
    "    sigmas[:, nz+1:,  :] = z.unsqueeze(1) - Ucols\n",
    "\n",
    "    # propagate through dynamics\n",
    "    sig_flat = sigmas.reshape(B*(2*nz+1), nz)\n",
    "    zprop = f_step(sig_flat, dt=dt).reshape(B, 2*nz+1, nz)\n",
    "\n",
    "    # weights\n",
    "    wm = torch.full((2*nz+1,), W, device=device, dtype=dtype)\n",
    "    wc = torch.full((2*nz+1,), W, device=device, dtype=dtype)\n",
    "    wm[0] = Wm0\n",
    "    wc[0] = Wc0\n",
    "\n",
    "    # predicted mean/cov\n",
    "    z_pred = (zprop * wm.view(1,-1,1)).sum(dim=1)\n",
    "    dz = zprop - z_pred.unsqueeze(1)\n",
    "    P_pred = torch.einsum(\"i,bij,bik->bjk\", wc, dz, dz) + Qz\n",
    "\n",
    "    # predicted measurement\n",
    "    yprop = h_meas(zprop.reshape(B*(2*nz+1), nz)).reshape(B, 2*nz+1, ny)\n",
    "    y_pred = (yprop * wm.view(1,-1,1)).sum(dim=1)\n",
    "    dy = yprop - y_pred.unsqueeze(1)\n",
    "    S = torch.einsum(\"i,bij,bik->bjk\", wc, dy, dy) + R\n",
    "    Pzy = torch.einsum(\"i,bij,bik->bjk\", wc, dz, dy)\n",
    "\n",
    "    # stabilize S\n",
    "    I_y = torch.eye(ny, device=device, dtype=dtype).unsqueeze(0)\n",
    "    S = S + jitter_S * I_y\n",
    "    S = make_spd(S, eps=jitter_S)\n",
    "\n",
    "    # gain and update\n",
    "    Ls = safe_cholesky(S, jitter=jitter_S)\n",
    "    # K = Pzy @ S^{-1} using Cholesky solves\n",
    "    tmp = torch.linalg.solve_triangular(Ls, Pzy.transpose(-1,-2), upper=False)\n",
    "    tmp = torch.linalg.solve_triangular(Ls.transpose(-1,-2), tmp, upper=True)\n",
    "    K = tmp.transpose(-1,-2)\n",
    "    e = y - y_pred\n",
    "    z_upd = z_pred + torch.einsum(\"bij,bj->bi\", K, e)\n",
    "    P_upd = P_pred - K @ S @ K.transpose(-1,-2)\n",
    "    P_upd = 0.5 * (P_upd + P_upd.transpose(-1,-2))\n",
    "    P_upd = make_spd(P_upd, eps=jitter_P)\n",
    "    return z_upd, P_upd, e, S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785a89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Causal window Transformer NoiseNet ---\n",
    "# It predicts Qx_k, R_k (full SPD via Cholesky factors) and a change logit p_k.\n",
    "# It only sees past features (phi up to k-1), so the whole pipeline is causal.\n",
    "\n",
    "class CausalWindowTransformerNoiseNet(nn.Module):\n",
    "    def __init__(self, d_in: int, d_model: int, nx: int, ny: int,\n",
    "                 W: int, n_layers: int, n_heads: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.nx, self.ny = nx, ny\n",
    "        self.nQ = n_tril(nx)\n",
    "        self.nR = n_tril(ny)\n",
    "        self.d_out = self.nQ + self.nR + 1\n",
    "\n",
    "        self.in_proj = nn.Linear(d_in, d_model)\n",
    "        self.pos = nn.Parameter(torch.zeros(1, W, d_model))\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=4*d_model,\n",
    "            dropout=dropout, batch_first=True, activation=\"gelu\", norm_first=True\n",
    "        )\n",
    "        self.enc = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "        self.head = nn.Linear(d_model, self.d_out)\n",
    "\n",
    "        # initialize to small-ish Q/R (stability)\n",
    "        with torch.no_grad():\n",
    "            self.head.weight.mul_(0.01)\n",
    "            self.head.bias.zero_()\n",
    "            self.head.bias[:nx] = -6.0               # Q diag logits\n",
    "            self.head.bias[self.nQ:self.nQ+ny] = -6.0 # R diag logits\n",
    "\n",
    "    def forward(self, phi_seq: torch.Tensor):\n",
    "        # phi_seq: (B,W,d_in)\n",
    "        B, W, _ = phi_seq.shape\n",
    "        h = self.in_proj(phi_seq) + self.pos[:, :W, :]\n",
    "        h = self.enc(h)\n",
    "        out = self.head(h[:, -1, :])  # last token as \"current\" prediction\n",
    "\n",
    "        qv = out[:, :self.nQ]\n",
    "        rv = out[:, self.nQ:self.nQ+self.nR]\n",
    "        p_logit = out[:, -1:]\n",
    "        return qv, rv, p_logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f45d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new datasets...\n",
      "  - Building Train (256 seq)...\n",
      "  - Building Val (64 seq)...\n",
      "  - Building Test (64 seq)...\n",
      "Saving datasets to ./data...\n",
      "Data generation and saving complete.\n",
      "Dataset Sizes -> Train: 256, Val: 64, Test: 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Dataset creation (in-memory): random k* per sequence ---\n",
    "# --- 데이터 저장 경로 설정 ---\n",
    "DATA_DIR = \"./data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train_data.pt\")\n",
    "VAL_FILE = os.path.join(DATA_DIR, \"val_data.pt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test_data.pt\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def build_dataset(n_seq: int, cfg: CFG):\n",
    "    dev, dt = cfg.device, cfg.dtype\n",
    "    data = []\n",
    "    for _ in range(n_seq):\n",
    "        kstar = random.randint(int(cfg.kstar_lo * cfg.T), int(cfg.kstar_hi * cfg.T))\n",
    "        x_true, theta_true, y = simulate_sequence(cfg.T, cfg.dt, cfg.jump_ratio, kstar, dev, dt)\n",
    "        p = make_p_label(cfg.T, kstar, cfg.p_label_width, dev, dt)\n",
    "        data.append({\"x_true\": x_true, \"theta_true\": theta_true, \"y\": y, \"p\": p, \"kstar\": kstar})\n",
    "    return data\n",
    "\n",
    "def sample_batch(data, cfg: CFG):\n",
    "    B = cfg.batch_size\n",
    "    T = cfg.T\n",
    "    seg = cfg.burn_in + cfg.L\n",
    "    idx = random.sample(range(len(data)), B)\n",
    "    s_max = T - seg - 1\n",
    "    starts = [random.randint(0, s_max) for _ in range(B)]\n",
    "\n",
    "    y = []\n",
    "    x = []\n",
    "    p = []\n",
    "    for i, s in zip(idx, starts):\n",
    "        d = data[i]\n",
    "        y.append(d[\"y\"][s:s+seg])\n",
    "        x.append(d[\"x_true\"][s:s+seg])\n",
    "        p.append(d[\"p\"][s:s+seg])\n",
    "\n",
    "    return torch.stack(y, 0), torch.stack(x, 0), torch.stack(p, 0)\n",
    "\n",
    "def prepare_datasets(cfg, force_generate=False):\n",
    "    \"\"\"\n",
    "    데이터 파일이 있으면 로드하고, 없으면 생성 후 저장합니다.\n",
    "    force_generate=True로 설정하면 무조건 새로 생성하고 덮어씁니다.\n",
    "    \"\"\"\n",
    "    # 1. 파일이 모두 존재하고, 강제 생성이 아닐 경우 -> 로드\n",
    "    if os.path.exists(TRAIN_FILE) and os.path.exists(VAL_FILE) and os.path.exists(TEST_FILE) and not force_generate:\n",
    "        print(f\"Loading datasets from {DATA_DIR}...\")\n",
    "        train_data = torch.load(TRAIN_FILE)\n",
    "        val_data = torch.load(VAL_FILE)\n",
    "        test_data = torch.load(TEST_FILE)\n",
    "        print(\"Data loaded successfully.\")\n",
    "    \n",
    "    # 2. 파일이 없거나 강제 생성일 경우 -> 생성 및 저장\n",
    "    else:\n",
    "        print(\"Generating new datasets...\")\n",
    "        # (1) Training Data\n",
    "        print(f\"  - Building Train ({cfg.n_train_seq} seq)...\")\n",
    "        train_data = build_dataset(cfg.n_train_seq, cfg)\n",
    "        \n",
    "        # (2) Validation Data\n",
    "        print(f\"  - Building Val ({cfg.n_val_seq} seq)...\")\n",
    "        val_data = build_dataset(cfg.n_val_seq, cfg)\n",
    "        \n",
    "        # (3) Testing Data (새로 추가됨)\n",
    "        print(f\"  - Building Test ({cfg.n_test_seq} seq)...\")\n",
    "        test_data = build_dataset(cfg.n_test_seq, cfg)\n",
    "        \n",
    "        # 저장\n",
    "        print(f\"Saving datasets to {DATA_DIR}...\")\n",
    "        torch.save(train_data, TRAIN_FILE)\n",
    "        torch.save(val_data, VAL_FILE)\n",
    "        torch.save(test_data, TEST_FILE)\n",
    "        print(\"Data generation and saving complete.\")\n",
    "        \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# --- 실행 ---\n",
    "# force_generate=True로 하면 기존 파일을 무시하고 새로 만듭니다.\n",
    "train_data, val_data, test_data = prepare_datasets(cfg, force_generate=False)\n",
    "\n",
    "print(f\"Dataset Sizes -> Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "\n",
    "# train_data = load_dataset(\"data/train_toy_T2000.pt\", cfg.device, cfg.dtype)\n",
    "# val_data   = load_dataset(\"data/val_toy_T2000.pt\",   cfg.device, cfg.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10c3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Differentiable rollout on one (burn-in + loss) window ---\n",
    "\n",
    "def rollout_window(net: nn.Module, y_seg: torch.Tensor, x_true_seg: torch.Tensor, p_label_seg: torch.Tensor, cfg: CFG):\n",
    "    \"\"\"\n",
    "    y_seg: (B,Tseg,ny), x_true_seg: (B,Tseg,nx), p_label_seg: (B,Tseg,1)\n",
    "    Returns dict(losses, trajectories)\n",
    "    \"\"\"\n",
    "    device, dtype = y_seg.device, y_seg.dtype\n",
    "    B, Tseg, ny = y_seg.shape\n",
    "    nx, nz = cfg.nx, cfg.nz\n",
    "\n",
    "    d_in = 2*ny + 2\n",
    "\n",
    "    # init z and P\n",
    "    q0 = y_seg[:, 0, :]\n",
    "    v0 = torch.zeros(B,2, device=device, dtype=dtype)\n",
    "    theta0 = torch.ones(B,1, device=device, dtype=dtype)\n",
    "    z = torch.cat([q0, v0, theta0], dim=-1)\n",
    "\n",
    "    P = torch.diag(torch.tensor([1e-2,1e-2, 1e-1,1e-1, 1e-2], device=device, dtype=dtype)).unsqueeze(0).repeat(B,1,1)\n",
    "\n",
    "    # feature buffer: past-only features\n",
    "    phi_buf = torch.zeros(B, cfg.W, d_in, device=device, dtype=dtype)\n",
    "\n",
    "    xhat, thetahat, ppred = [], [], []\n",
    "    qv_hist, rv_hist = [], []\n",
    "\n",
    "    for t in range(Tseg):\n",
    "        # 1) predict Qx_k, R_k, p_k from past feature window\n",
    "        qv, rv, p_logit = net(phi_buf)\n",
    "        p = torch.sigmoid(p_logit)\n",
    "\n",
    "        # 2) build full SPD Qx and R via Cholesky\n",
    "        Lq = vec_to_cholesky(qv, nx)\n",
    "        Qx = chol_to_spd(Lq)\n",
    "        Lr = vec_to_cholesky(rv, ny)\n",
    "        R = chol_to_spd(Lr)\n",
    "\n",
    "        # 3) gate Q_theta,k using p_k (THIS is the key location)\n",
    "        qtheta = (1.0 - p) * cfg.Qtheta_base + p * cfg.Qtheta_jump\n",
    "        Qt = qtheta.view(B,1,1)\n",
    "        Qz = blockdiag(Qx, Qt)\n",
    "\n",
    "        # 4) UKF update\n",
    "        z, P, e, S = ukf_step(\n",
    "            z, P, y_seg[:, t, :], Qz, R,\n",
    "            dt=cfg.dt, alpha=cfg.alpha, beta=cfg.beta, kappa=cfg.kappa,\n",
    "            jitter_P=cfg.jitter_P, jitter_S=cfg.jitter_S\n",
    "        )\n",
    "\n",
    "        # 5) create phi_t and append to buffer (for next step)\n",
    "        phi_t = make_phi(e, S, jitter=cfg.jitter_S)\n",
    "        phi_buf = torch.cat([phi_buf[:, 1:, :], phi_t.unsqueeze(1)], dim=1)\n",
    "\n",
    "        xhat.append(z[:, :nx])\n",
    "        thetahat.append(z[:, nx:nx+1])\n",
    "        ppred.append(p_logit)\n",
    "        qv_hist.append(qv)\n",
    "        rv_hist.append(rv)\n",
    "\n",
    "    xhat = torch.stack(xhat, 1)\n",
    "    thetahat = torch.stack(thetahat, 1)\n",
    "    ppred = torch.stack(ppred, 1)\n",
    "    qv_hist = torch.stack(qv_hist, 1)\n",
    "    rv_hist = torch.stack(rv_hist, 1)\n",
    "\n",
    "    start = cfg.burn_in\n",
    "    end = cfg.burn_in + cfg.L\n",
    "\n",
    "    x_loss = F.mse_loss(xhat[:, start:end, :], x_true_seg[:, start:end, :])\n",
    "    bce = F.binary_cross_entropy_with_logits(ppred[:, start:end, :], p_label_seg[:, start:end, :])\n",
    "\n",
    "    dq = (qv_hist[:, start+1:end, :] - qv_hist[:, start:end-1, :]).pow(2).mean()\n",
    "    dr = (rv_hist[:, start+1:end, :] - rv_hist[:, start:end-1, :]).pow(2).mean()\n",
    "    smooth = dq + dr\n",
    "\n",
    "    q_off = qv_hist[:, start:end, nx:]\n",
    "    r_off = rv_hist[:, start:end, ny:]\n",
    "    offdiag = (q_off.pow(2).mean() + r_off.pow(2).mean())\n",
    "\n",
    "    loss = cfg.w_state*x_loss + cfg.w_bce*bce + cfg.w_smooth*smooth + cfg.w_offdiag*offdiag\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"x_loss\": x_loss.detach(),\n",
    "        \"bce\": bce.detach(),\n",
    "        \"smooth\": smooth.detach(),\n",
    "        \"offdiag\": offdiag.detach(),\n",
    "        \"xhat\": xhat.detach(),\n",
    "        \"thetahat\": thetahat.detach(),\n",
    "        \"ppred\": ppred.detach(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4605cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minhy\\AppData\\Local\\Temp\\ipykernel_24824\\4182933182.py:21: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  self.enc = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n"
     ]
    },
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.cholesky: (Batch element 6): The factorization could not be completed because the input is not positive-definite (the leading minor of order 4 is not positive-definite).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_LinAlgError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg.steps_per_epoch):\n\u001b[32m     19\u001b[39m     y_seg, x_seg, p_seg = sample_batch(train_data, cfg)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     out = \u001b[43mrollout_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     opt.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     23\u001b[39m     out[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m].backward()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mrollout_window\u001b[39m\u001b[34m(net, y_seg, x_true_seg, p_label_seg, cfg)\u001b[39m\n\u001b[32m     42\u001b[39m Qz = blockdiag(Qx, Qt)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 4) UKF update\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m z, P, e, S = \u001b[43mukf_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_seg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjitter_P\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjitter_P\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter_S\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjitter_S\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 5) create phi_t and append to buffer (for next step)\u001b[39;00m\n\u001b[32m     52\u001b[39m phi_t = make_phi(e, S, jitter=cfg.jitter_S)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mukf_step\u001b[39m\u001b[34m(z, P, y, Qz, R, dt, alpha, beta, kappa, jitter_P, jitter_S)\u001b[39m\n\u001b[32m     62\u001b[39m I = torch.eye(nz, device=device, dtype=dtype).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     63\u001b[39m Pj = make_spd(P, eps=jitter_P)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m U = \u001b[43msafe_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjitter_P\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# robust (B,nz,nz) lower\u001b[39;00m\n\u001b[32m     65\u001b[39m U = U * math.sqrt(c)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# sigma points\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36msafe_cholesky\u001b[39m\u001b[34m(A, jitter, max_tries)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# fallback: eigen projection then cholesky\u001b[39;00m\n\u001b[32m     21\u001b[39m A = make_spd(A, eps=jitter)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31m_LinAlgError\u001b[39m: linalg.cholesky: (Batch element 6): The factorization could not be completed because the input is not positive-definite (the leading minor of order 4 is not positive-definite)."
     ]
    }
   ],
   "source": [
    "# --- Train ---\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "d_in = 2*cfg.ny + 2\n",
    "net = CausalWindowTransformerNoiseNet(\n",
    "    d_in=d_in, d_model=cfg.d_model, nx=cfg.nx, ny=cfg.ny,\n",
    "    W=cfg.W, n_layers=cfg.n_layers, n_heads=cfg.n_heads, dropout=cfg.dropout\n",
    ").to(cfg.device)\n",
    "\n",
    "opt = torch.optim.AdamW(net.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
    "\n",
    "for ep in range(cfg.epochs):\n",
    "    net.train()\n",
    "    loss_sum = x_sum = bce_sum = 0.0\n",
    "\n",
    "    for it in range(cfg.steps_per_epoch):\n",
    "        y_seg, x_seg, p_seg = sample_batch(train_data, cfg)\n",
    "        out = rollout_window(net, y_seg, x_seg, p_seg, cfg)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        out[\"loss\"].backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        loss_sum += float(out[\"loss\"].detach())\n",
    "        x_sum += float(out[\"x_loss\"])\n",
    "        bce_sum += float(out[\"bce\"])\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        yv, xv, pv = sample_batch(val_data, cfg)\n",
    "        outv = rollout_window(net, yv, xv, pv, cfg)\n",
    "\n",
    "    print(f\"[ep {ep+1}/{cfg.epochs}] \"\n",
    "          f\"train loss {loss_sum/cfg.steps_per_epoch:.4f} (x {x_sum/cfg.steps_per_epoch:.4f}, bce {bce_sum/cfg.steps_per_epoch:.4f}) | \"\n",
    "          f\"val loss {float(outv['loss']):.4f} (x {float(outv['x_loss']):.4f}, bce {float(outv['bce']):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Full 2000-step rollout + plots around k* ---\n",
    "\n",
    "@torch.no_grad()\n",
    "def rollout_full(net: nn.Module, y: torch.Tensor, cfg: CFG):\n",
    "    \"\"\"\n",
    "    y: (T,ny)\n",
    "    returns xhat (T,nx), thetahat (T,1), p (T,1)\n",
    "    \"\"\"\n",
    "    device, dtype = cfg.device, cfg.dtype\n",
    "    ny, nx = cfg.ny, cfg.nx\n",
    "    d_in = 2*ny + 2\n",
    "\n",
    "    q0 = y[0:1, :]\n",
    "    v0 = torch.zeros(1,2, device=device, dtype=dtype)\n",
    "    theta0 = torch.ones(1,1, device=device, dtype=dtype)\n",
    "    z = torch.cat([q0, v0, theta0], dim=-1)\n",
    "\n",
    "    P = torch.diag(torch.tensor([1e-2,1e-2, 1e-1,1e-1, 1e-2], device=device, dtype=dtype)).unsqueeze(0)\n",
    "    phi_buf = torch.zeros(1, cfg.W, d_in, device=device, dtype=dtype)\n",
    "\n",
    "    xhat = torch.zeros(cfg.T, nx, device=device, dtype=dtype)\n",
    "    thetahat = torch.zeros(cfg.T, 1, device=device, dtype=dtype)\n",
    "    p = torch.zeros(cfg.T, 1, device=device, dtype=dtype)\n",
    "\n",
    "    for t in range(cfg.T):\n",
    "        qv, rv, p_logit = net(phi_buf)\n",
    "        p_t = torch.sigmoid(p_logit)\n",
    "\n",
    "        Lq = vec_to_cholesky(qv, nx)\n",
    "        Qx = chol_to_spd(Lq)\n",
    "        Lr = vec_to_cholesky(rv, ny)\n",
    "        R = chol_to_spd(Lr)\n",
    "\n",
    "        qtheta = (1.0 - p_t) * cfg.Qtheta_base + p_t * cfg.Qtheta_jump\n",
    "        Qt = qtheta.view(1,1,1)\n",
    "        Qz = blockdiag(Qx, Qt)\n",
    "\n",
    "        z, P, e, S = ukf_step(\n",
    "            z, P, y[t:t+1, :], Qz, R,\n",
    "            dt=cfg.dt, alpha=cfg.alpha, beta=cfg.beta, kappa=cfg.kappa,\n",
    "            jitter_P=cfg.jitter_P, jitter_S=cfg.jitter_S\n",
    "        )\n",
    "\n",
    "        phi_t = make_phi(e, S, jitter=cfg.jitter_S)\n",
    "        phi_buf = torch.cat([phi_buf[:, 1:, :], phi_t.unsqueeze(1)], dim=1)\n",
    "\n",
    "        xhat[t] = z[0, :nx]\n",
    "        thetahat[t] = z[0, nx:nx+1]\n",
    "        p[t] = p_t[0]\n",
    "\n",
    "    return xhat, thetahat, p\n",
    "\n",
    "# pick one validation sequence\n",
    "d = random.choice(val_data)\n",
    "kstar = d[\"kstar\"]\n",
    "y = d[\"y\"]\n",
    "theta_true = d[\"theta_true\"]\n",
    "\n",
    "xhat, thetahat, p = rollout_full(net, y, cfg)\n",
    "\n",
    "# compute \"adaptation time\" to be within 5% of new theta\n",
    "theta_new = theta_true[kstar, 0].item()\n",
    "tol = 0.05 * theta_new\n",
    "err = (thetahat[:,0] - theta_true[:,0]).abs()\n",
    "after = err[kstar:]\n",
    "idx = (after < tol).nonzero(as_tuple=False)\n",
    "t_adapt = int(idx[0].item()) if idx.numel() > 0 else None\n",
    "\n",
    "print(\"k* =\", kstar)\n",
    "print(\"theta_new =\", theta_new, \"| tol(5%) =\", tol)\n",
    "print(\"first time within tol after k*:\", t_adapt, \"steps (target <= 100)\")\n",
    "\n",
    "# plot theta and p around k*\n",
    "w = 250\n",
    "a = max(0, kstar - w)\n",
    "b = min(cfg.T, kstar + w)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(theta_true[a:b,0].cpu().numpy(), label=\"theta true\")\n",
    "plt.plot(thetahat[a:b,0].cpu().numpy(), label=\"theta hat\")\n",
    "plt.axvline(x=kstar-a)\n",
    "plt.title(\"Theta jump and estimate (zoomed)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(p[a:b,0].cpu().numpy())\n",
    "plt.axvline(x=kstar-a)\n",
    "plt.title(\"p_k (change probability) (zoomed)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
